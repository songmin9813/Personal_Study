# 1,2 모의고사 오답
## 1회 모의고사 오답
- 데이터 변환 기법에는 데이터의 노이즈를 구간화, 군집화 등으로 다듬는 평활화. 다양한 차원으로 요약하는 집계, 특정 구간으로 값을 스케일링하는 일반화, 정해진 구간으로 전환하는 정규화, 새로운 속성을 생성하는 기법 등이 있다.


- 데이터 레이크 : 정형, 비정형의 다양한 유형의 데이터를 저장, 관리하며 소스 데이터의 형태를 그대로 저장하기 때문에 메타의 관리가 중요하다.
  - 데이터 레이크에 저장되는 방대한 데이터에서 효율적으로 유의미한 데이터를 활용하기 위해 레이크쇼어 마트를 구성하여 사용하기도 한다.


- 분석 스킬의 종류 
  - Soft Skill : 분석의 통찰력, 여러 분야의 협력 능력, 설득력 있는 전달력
  - Hard Skill : 빅데이터 관련 이론적 지식, 분석기술의 숙련도


- 데이터 수집 프로세스 : 수집 데이터 도출 - 수집 데이터 목록화 - 데이터 소유 기관 확인 및 협의 - 데이터 유형 확인 및 분류 - 데이터 수집 기술 선정 - 수집 계획서 작성 - 수집 주기 정의 - 데이터 수집


- 릿지(Lidge)는 L2-규제를 통해 제약을 주는 방법이다.


- 차원 축소 기법의 종류 : 주성분 분석(PCA), 특이값 분해(SVD), 요인 분석, **독립 성분 분석(ICA)**, 다차원 척도법(MDS)가 있다.


- 왼쪽 꼬리 분포의 왜도를 가지고 있는 경우 평균<중위수<최빈값의 크기를 가진다. **편포에 상관없이 중위수는 항상 가운데 위치함에 유의한다.**


- 공분산 값의 크기는 측정 단위에 따라 달라지므로 선형 관계의 강도를 나타내지는 못한다.


- 코로플레스 지도 : 어떤 데이터 수치에 따라 지정한 색상 스케일로 영역을 칠하여 표현하는 방법(=등치지역도)


- 층화추출 : 모집단을 어떤 특성에 따라 서로 겹치지 않는 여러 계층으로 나누고, 계층별로 무작위 추출을 수행하는 방식


- 다중 회귀 모형에 개별 회귀 계수를 검정하는 통계량은 F-통계량이다.


- 로지스틱 회귀 분석은 종속변수가 범주형 데이터일 때 사용한다.


- 분리 기준으로는 카이제곱 통계량을 사용하고, 분리 방법은 다지 분리를 사용하는 의사결정나무 알고리즘은 CHAID이다.


- 재현율 : 실제값이 Positive인 데이터(TP+FN) 중 모형이 Positive로 예측한(TP) 데이터의 비율
- 거짓 긍정률 : 실제 Negative 데이터 중 Positive로 잘못 예측한 비율.
- **혼동 행렬 분석에 대해서 한 번 더 짚을 필요가 있어보임**

- 선형 회귀 모형의 가정
  - 등분산성 : 오차항의 분산은 등분산이어야 한다.
  - 선형성 : 종속변수는 독립변수의 선형 함수여야 한다.
  - 독립성 : 독립변수 사이에는 상관관계가 없어야 한다.
  - 정규성 : 가설검증이 정규분포를 따라야 한다.


- 더빈-왓슨 검정은 선형회귀 모형의 독립성을 확인할 때 사용할 수 있는 진단방법이다.


- z-검정의 귀무가설은 표본 평균이 모집단의 평균과 같다는 것이다.

- 카이제곱 검정은 **범주형 데이터**에 사용되며 데이터가 예상되는 분포에 얼마나 잘 맞는지를 검정한다. 이 때의 **귀무가설은 데이터가 특정 확률을 따른다**이며, 반대로 **대립가설은 데이터가 특정 확률을 따르지 않는다**가 된다.

- 유연성이 큰 분석 모형은 상대적으로 **복잡한 모형이다.** 복잡한 모형은 편향은 작고 분산은 크게 나타난다.

- 설명력이 높은 분석 모형은 상대적으로 성능이 떨어진다는 단점이 있다.

- 정보 구조화 : 데이터를 수집하고 정제하면서 시각화의 목표가 될만한 것을 발견하거나 설정하는 단계이다. 데이터를 유사한 것끼리 묶거나 재배열하여 데이터의 패턴을 찾아낸다.

- 관게 시각화 방법의 종류 : 산점도, 산점도 행렬, 버블차트, 히스토그램
- 비교 시각화의 종류 : 히트맵, 스타 차트, 체르노프 페이스, 평행 좌표 그래프

- 분석 모형 리모델링 단계에서 최종 분석 모형 선정 시에 사용했던 평가지표를 활용하기에 분석 모형 평가 지표 선정은 수행하지 않는다.

## 2회 모의고사 오답

- 데이터 확보 계획 단계 : 목표 정의 - 요구 사항 도출 - 예산안 수립 - 계획 수립

- 언어, 문자 등 정형화되지 않아 저장, 검색, 분석에 많은 비용이 소모되는 데이터는 정성적 데이터이다.

- NoSQL의 유형은 데이터 저장 모델에 따라 Key Value Database, Document Database, Wide Column Database, Graph Database로 이루어진다.

- KDD 분석 방법론의 분석 단계 : 데이터 선택 - 데이터 전처리 - 데이터 변환 - 데이터 마이닝 - 해석과 평가

- 시급성에 기준을 두고 분석 업무의 우선순위를 정할 때 난이도가 낮고 시급한 문제를 먼저 해결해야 한다.
  - 난이도가 높다면 시급성보다 난이도를 우선하도록 한다.

- 아마존 AWS에서 제공하는 파일 시스템 저장소는 S3(Simple Storage Service)이다.

- 관측치가 기록된 값을 결측값으로 처리하여 분석에 활용할는 것은 옳지 않다. 기본값이 기록된 경우라도 그 값의 의미를 가지고 있기 때문에 결측값 처리에 유의하여야 한다.

- 군집 분석은 이상값 판정에 이용되는 것이 아니라, 성질이 다른 군집으로 나눌 때 이용된다.

- 주성분 분석 : 서로 상관성이 높은 변수들의 선형 결합으로 만들어 기존의 상관성이 높은 변수들을 요약 및 축소하는 기법
  - 분석을 통해 나타나는 주성분으로 변수들 사이의 구조를 쉽게 이해하기는 어렵다.

- 히스토그램은 표본의 크기가 작으면 각 막대의 높이가 데이터 분포의 형상을 잘 표현해내지 못한다.

- 연속형 확률변수는 가능한 값이 실수의 특정 구간 전체에 해당하는 확률변수이며 연속형 확률 밀도 함수를 가진다.

- t-분포 : 연속형 확률 분포 중 표준 정규 분포와 같이 평균이 0을 중심으로 좌우가 동일한 분포를 따른다.
  - 두 집단의 평균이 동일한지 알고자 할 때 검정 통계량으로 사용된다.

- p-value는 귀무가설이 사실인데도 불구하고 사실이 아니라고 판정할 때의 실제 확률을 나타낸다.

- 해지 여부를 예측하는 분석을 진행하는 경우 지도 학습 분류 분석을 진행한다.

- 독립변수의 수는 변수에 대한 영향력 비교와 무관하다.

- 지니계수는 각 변수가 나올 확률을 제곱하여 더하는 방식으로 계산된다.

- 다중 회귀 분석은 회귀 예측 모델로 구분한다.

- 지지도는 연관성 분석에 사용하는 개념이다. 서포트 벡터 머신은 다른 모델에 비해 과적합의 위험이 낮다.

- k 평균 군집 분석은 비계층적 군집 분석의 한 방식이다.

- 평균이 일정하지 않은 경우 차분을 통해 정상화한다.(시계열 분석0

- 비모수적 기법은 **순위와 부호를 기반으로 하여 이상치의 영향이 작다.**

- 정밀도 : Positive로 예측한 데이터 중 실제 Positive인 데이터의 비율

- 교차 검증을 사용하면 다양한 검증 데이터에 대해 하이퍼파라미터 튜닝을 하기에 일반화 성능이 올라간다.

- 홀드아웃은 데이터를 학습 데이터와 검증 데이터로 어떻게 나누느냐에 따라 성능 값의 차이가 발생한다.

- k fold는 데이터를 여러 번 분할하여 성능을 계산한 후 평균값을 구하므로, 데이터 분할에 따른 성능 차이가 상쇄된다.
  - **홀드아웃이 k-fold보다 학습 데이터 분할에 더 민감하다고 볼 수 있다.**

- 카이제곱 검정은 두 개 이상의 변수가 독립인지 검정할 때도 사용할 수 있다.
  - 독립성 검정, 적합도 검정, 동질성 검정에도 사용이 가능

- 순열 변수 중요도 : 변수의 값을 무작위로 섞어 해당 변수를 노이즈처럼 만드는 방법. 변수 중요도를 평가하는 방법임
  - 변수값을 무작위로 섞기에 변수 중요도를 구할때마다 조금씩 달라질 수 있지만 변수 제거와 분석 모형 학습을 반복하는 일을 하지 않아도 된다.

- 히스토그램 : 막대그래프와 유사한 형태. 데이터의 도수 분포를 막대 형태로 시각화하여 보여 주는 방법이다.
  - x축이 데이터의 구간을 나타내므로 시간의 흐름에 따른 변화를 살펴보기에는 적합하지 않다.

- 분석 모형 전개 : 데이터를 분석한 결과를 확장 적용하기 위한 단계

- 차트 및 시각화 도구 선택은 분석 결과 활용 시나리오 개발 단계에서 이루어진다. 
  - 업무 담당자에게 제공된 분석 결과를 위한 시각화 방법을 모색하는 것도 이 단계에서 이루어짐