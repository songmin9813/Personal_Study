# 3. 빅데이터 모델링
## 1. 분석 모형 설계
#### 분석 방법
- **통계 분석**(Statistical analysis) : 특정 집단이나 불확실한 현상을 데이터를 통해 이해하고 추론을 통해 의사결정하는 과정
  - 기술 통계 : 데이터를 요약/정리하고 이해하기 위해 평균, 표준편차 등 기초통계량을 구하거나 그래프로 표현하는 분석방식
  - 추론 통계 : 수집된 데이터를 기반으로 모집단에 대해 추정하고 가설을 검정하는 분석 방법
- **데이터 마이닝**(Data Mining) : 데이터에 숨어있는 유용한 정보를 찾아내는 과정. 분류 분석, 추정 분석, 예측 분석, 연관 분석, 군집 분석, 기술 분석 등이 존재
- **머신 러닝**(Machine Learning) : 분석 모형 알고리즘이 데이터를 학습하고 학습한 정보를 바탕으로 결과를 출력하는 분석방법. 종속변수의 존재 여부, 학습 방법 등에 따라 지도 학습, 비지도 학습, 강화학습으로 구분함
  - **지도 학습**(Supervised Learning) : 정답에 해당하는 종속변수가 포함되어 있는 데이터를 학습. 종속변수와 독립변수 간의 관계를 분석하여 분류, 예측 등의 문제를 해결함. 종속변수가 연속형인 경우 수치 예측, 범주형인 경우 분류 예측을 시행한다.
    - **지도 학습의 종류** : 회귀 분석, 로지스틱 회귀분석, 나이브 베이즈, KNN, 의사결정나무, 인공신경망, SVM, 랜덤포레스트
  - **비지도 학습**(Unsupervised Learning) : 종속변수가 포함되지 않는 데이터를 학습. 예측 문제보다는 현상 설명, 특징 도출, 패턴 도출 등의 문제를 해결한다.
    - **비지도 학습의 종류** : 군집화(K-means, SOM, 계층군집), 차원 축소(주성분분석, 선형판별분석), 연관분석, 자율학습 인공신경망


#### 데이터 유형에 따른 모형 구분
|데이터 유형|연속형 종속변수|범주형 종속변수|종속변수 없음|
|----|----|----|--------|
|연속형 독립변수|회귀분석 트리 모형,인공신경망,SVR,KNN|로지스틱 회귀분석 트리 모형, 인공신경망, SVM, KNN|주성분 분석, 군집 분석|
|범주형 독립변수|회귀분석, t-test, ANOVA, 트리 모형, 인공신경망|로지스틱 회귀분석, 카이제곱 검정, 트리 모형, 인공신경망, 나이브베이즈|연관 분석, 판별분석|
|연속형+범주형 독립변수|회귀분석, 트리 모형, 인공신경망|트리 모형, 인공신경망|상관 분석|


#### 변수 선택
- 전진 선택법 : 상관관계가 큰 변수부터 순차적으로 모형에 추가하며 변수를 추가하는 방법
- 후진 제거법 : 모든 독립변수를 추가한 모형에서 상관관계가 작은 변수부터 순차적으로 제거하는 방법
- 단계적 선택법 : 전진 선택법으로 순차적으로 변수를 추가하면서 중요도가 약해진 변수를 후진 제거법으로 제거하는 방법


#### 파라미터와 하이퍼 파라미터
- 파라미터 : 모형 내부 요소로 모형의 성능에 직접적인 영향을 미친다. 모형이 데이터를 학습한 결과 값으로 자동으로 결정된다.
- **하이퍼 파라미터** : 모형 외부 요소로 모형의 성능에 간접적인 영향을 미친다. 사용자가 설정하는 값으로 학습 과정에 영향을 주고 학습 결과인 파라미터 값에 영향을 준다.
- 하이퍼 파라미터 튜닝 방법
  - **매뉴얼 서치**(Manual Search) : 사용자가 직감 또는 경험에 근거하여 직접 하이퍼 파라미터를 조합하고 조정하는 방법. 매우 비효율적인 방법
  - **그리드 서치**(Grid Search) : 가능한 모든 조합을 시도하여 최적의 파라미터 값을 찾는 방법. 후보를 직접 선정하므로 후보 내에서 가장 좋은 결과를 얻을 수 있으나 후보가 아닌 값은 시도하지 않는다.
  - **랜덤 서치**(Random Search) : 하이퍼 파라미터의 값 범위를 지정하고 무작위 표본추출을 통해 생성한 조합을 시도하여 최적의 파라미터 값을 찾는 방법. 그리드 서치와 거의 동일하나 그리드 서치의 단점을 보완한다. **난수를 통해 확률적으로 탐색하므로 불필요한 값의 중복을 없앤다는 특징**을 가진다.


#### 데이터 분할
- **홀드아웃**(Hold-Out) : 가장 보편적인 방법으로 랜덤 추출을 통해 데이터를 분할함. 일반적으로 학습 데이터와 검증 데이터를 60-80%, 테스트 데이터를 20-40%로 분할한다.
- **K-fold 교차 검증** : 테스트 데이터를 제외한 데이터를 무작위로 중복되지 않는 K개의 데이터로 분할한다. (K-1)개의 데이터를 학습 데이터로 사용하고 나머지 1개 데이터를 검증 데이터로 사용한다. 이후 검증 데이터를 바꾸며 K번 반복하여 분할된 데이터가 한 번씩 검증 데이터로 사용된다.
- **부트스트랩**(Bootstrap) : 데이터의 분포가 치우쳐 있거나 데이터 건수가 너무 적을 때 사용 가능한 기법이다. 복원 추출을 통해 전체 데이터와 동일한 사이즈의 샘플 데이터를 추출한다. 어떤 데이터는 부트스트랩 샘플에 한 번 이상 포함되나 어떤 데이터는 한 번도 포함되지 않을 수 있다. 데이터의 사이즈가 충분히 크다면 전체 데이터의 약 63.2%를 포함한다.
- 데이터가 부족한 경우 검증용 데이터는 분할하지 않기도 한다.


#### 분석 모형 구축의 절차
- 요건 정의-모델링-검증 및 테스트-적용 단계로 구성
1. **요건 정의** : 기획 단계에서 도출한 내용을 요건 정의로 구체화하는 단계. **요구사항 도출-분석 추진 계획 수립-요구사항 확정**으로 이루어짐
2. **모델링** : 정의된 요건에 따라 본격적인 분석을 수행하는 단계. 데이터 준비 및 탐색적 데이터 분석을 수행하고 모델링과 성능 평가를 반복 수행하여 최종 모형을 선정한다. **데이터 마트 설계 및 구축-탐색적 분석 및 유의변수 도출-모델링-모델 성능 평가**로 이루어짐
3. **검증 및 테스트** : 분석 모형을 가상 운영 환경에서 테스트하는 단계. **운영 환경 테스트-비즈니스 영향도 평가**로 이루어짐
4. **적용** : 분석 결과를 실제 운영 환경에 적용하는 단계. **운영 시스템 적용-주기적 모델 업데이트**로 이루어짐


## 2. 분석 기법 적용
#### 회귀분석의 가정
- 선형성 : 독립변수와 종속변수는 선형적. 종속변수는 독립변수와 회귀계수의 선형적 조합으로 표현 가능. 산점도를 통해 선형성을 확인 가능
- 독립성 : 단순 회귀분석에는 잔차와 독립변수의 값이 서로 독립. 다중 회귀분석에서는 독립변수 간에 상관성 없이 독립
- 등분산성 : 잔차의 분산이 독립변수와 무관하게 일정. 잔차가 고르게 분포해야 함
- 정규성 : 잔차항이 정규분포의 형태를 띰. 잔차항의 평균은 0이고 분산이 일정함.

회귀분석의 위의 네 가정을 만족하는 데이터의 경우에 사용한다.


#### 회귀분석의 종류
- 단순 회귀 : 독립변수가 1개이며 종속변수와의 관계가 직선
- 다중 회귀 : 독립변수가 k개이며 종속변수와의 관계가 선형
- 다항 회귀 : 독립변수와 종속변수와의 관계가 1차 함수 이상인 관계
- 곡선 회귀 : 독립변수가 1개이며, 종속변수와의 관계가 곡선
- 비선형 회귀 : 회귀식의 모양이 미지의 모수들의 선형관계로 이뤄져있지 않은 모형


#### 단순선형 회귀분석
- 독립변수와 종속변수가 한 개씩 있으며 오차항이 있는 선형관계로 이뤄진다.(직선관계)
- 회귀계수는 최소제곱법을 사용하여 추정한다.
- 결정계수(R의 제곱)는 회귀 모형의 설명력을 보여주는 지표이며 회귀선의 정확도를 평가한다.
  - R의 제곱=회귀제곱합/전체제곱합


#### 다중선형 회귀분석
- 독립변수가 k개인 경우. 독립변수와 종속변수와의 관계는 1차 함수 이상인 경우이며 선형이다.
- 모형의 통계적 유의성은 F-통계량으로 확인하며, p-value가 0.05보다 작으면 회귀식이 통계적으로 유의하다고 본다.
- 다중선형 회귀분석의 검정
  - 회귀계수의 유의성 : 회귀계수의 유의성은 t-통계량을 통해 확인
  - 결정계수(R제곱) : 회귀 모형의 설명력을 보여주는 지표
  - 모형의 적합성 : 잔차와 종속변수의 산점도로 확인
  - 다중공선성 : 설명 변수들 사이에 선형관계가 존재하여 회귀계수의 추정에 부정적인 영향을 미치는 것을 의미


#### 규제가 있는 회귀 분석
- 릿지 회귀(Lidge)
  - 높은 상관관계가 있는 변수 간 검청 오차(또는 검정 MSE)가 최소인 모델을 찾는 것을 목적으로 가진다.
  - 규제항을 비용 함수에 추가하며, 모델의 훈련이 끝나면 모델의 성능을 규제 없는 성능 지표로 평가한다.
  - 알파는 모델을 얼마나 많이 규제할지 조절하는 것으로, 값이 커질수록 모든 가중치가 0에 수렴한다.
  - L2 규제 : 모든 파라미터 제곱만큼의 크기를 규제하는 방식. 가중치를 제약하여 가중치 값을 널리 퍼지도록 하는 효과를 준다.

- 라쏘 회귀(Lasso)
  - 변수 선택을 통해 변수 간 검정오차(또는 검정 MSE)가 최소인 모델을 찾는 것을 목적으로 가진다.
  - 릿지와 마찬가지로 규제항을 추가하지만 제곱이 아닌 절댓값을 적용한 값임
  - 알파의 값이 설정되면 중요하지 않은 변수들의 가중치가 0이 되어 제거되기에 해당 변수가 없는 것과 마찬가지가 된다.
  - L1 규제 : 가중치 벡터를 0으로 규제하는 방식. 의미있는 변수만을 선택하는 효과를 준다.
  - 다중공선성이 있는 경우에는 다중공선성이 발생하는 변수 그룹의 모든 변수가 제거되는 경우가 발생할 수 있어 릿지 회귀보다 성능이 떨어질 수 있다. 

- 엘라스틱넷 회귀(Elastic Net)
  - 릿지와 라쏘 회귀의 절충안. 두 회귀의 규제항을 단순히 더하여 사용하며 혼합 비율을 조절하여 어느 방식의 비중을 크기 할 것인지 결정한다.


#### 로지스틱 회귀분석
- 독립변수의 선형결합을 이용해 사건의 발생 여부를 예측하며, 종속변수가 범주형일 경우에 사용하는 회귀분석
- 종속변수의 범주가 두 개일 때 이항 로지스틱 회귀분석이라 하고, 그 이상이면 다항 로지스틱 회귀분석이라 함
- 일반적인 선형 회귀분석은 x값과 y값 모두 연속적인 값을 가진다. 하지만 로지스틱 회귀분석의 경우,  y값을 0~1(확률 P) 사이의 값을 갖게 하고 두 가지고 분류하려고 하는 과정이므로 수식을 변환하는 과정이 필요하다.
- 선형 회귀분석은 정규분포를 따르지만, 로지스틱 회귀분석은 이항분포를 따른다는 차이점이 있다.
- 모형 적합성
  - 모형의 유의성 : 모형이 설명하지 못하는 데이터의 정도를 의미하는 Deviance(이탈도)를 통해 검증. 이탈도가 적을수록 유리함
  - 계수의 유의성 : 왈드(ward) 검정을 통해 독립변수가 종속변수에 미치는 영향 확인. 검정 통계량인 z-value의 p-value가 유의수준보다 작으면 계수가 유의함
  - 모형의 설명력 : 로지스틱 회귀분석은 보통 결정계수가 낮게 나오는 편이므로, McFadden이 제안한 의사결정계수를 사용하는 것이 일반적임. AIC값이 작을수록 설명력이 좋음


#### 의사결정나무 분석
- 과거에 수집된 자료를 분석해서 이들 사이에 존재하는 패턴을 나타내는 분류모형을 나무모형으로 나타낸 것. 전체 자료를 여러 개의 소집단으로 분류하거나 예측하는 데 사용되는 기법
- 분석 과정
  - 의사결정 나무의 성장 : 데이터의 구조에 따라 분리 기준과 정지 규칙을 설정한다.
  - 정지 규칙 : 더 이상 트리가 분리되지 않도록 하는 규칙을 설정한다.
  - 가지치기 : 불필요한 가지를 제거하여 모형의 복잡도를 줄이는 과정
- 장점
  - 해석의 용이성 : 나무 구조로 표현되어 사용자의 이해가 쉬움
  - 상호작용 효과의 해석 가능 : 두 개 이상의 변수의 영향 정도를 쉽게 파악
  - 비모수적 모형 : 선형성, 정규성, 등분산성 등의 가정을 필요로 하지 않는 비모수적인 방법. 이상값에 민감하지 않음
  - 유연성, 정확도 높음 : 대용량 데이터에서도 빠르게 생성할 수 있다.
- 단점
  - 비연속성 : 연속형 변수를 비연속적 값으로 취급하여 분리 경계점에서는 예측오류가 커짐
  - 선형성 결여 : 각 변수의 고유한 영향력을 해석하기 어려움
  - 비안정성 : 학습용 자료에 의존하여 과대 적합 발생 가능성이 높음



#### 인공신경망 분석
- 사람 두뇌의 신경세포인 뉴런이 전기신호를 전달하는 모습을 모방한 기계학습 모델. 간단한 계산능력을 가진 처리 단위인 뉴런/노드들이 복잡하게 연결된 구조를 이루고 있으며, 입력데이터를 기초로 가중치를 통해 의사결정을 함
- 인공신경망의 구조
  - 활성 함수 : 노드에 입력된 값을 비선형 함수에 통과시켜 다음 노드로 전달하는데, 이 비선형 함수를 활성 함수라 함
    - Sigmoid 함수 : 로지스틱 함수라고도 함. 곡선의 형태로 0과 1사이의 값을 출력. 은닉층을 거칠 때마다 값이 0으로 수렴하는 문제를 가짐
    - ReLU 함수 : 입력값이 0보다 작으면 0을, 0보다 크면 입력값을 그대로 출력하는 함수. 연산이 빠르지만 0보다 작은 값에 대해 뉴런이 작동하지 않을 수 있음
    - Tanh 함수 : Sigmoid의 확장 형태. -1과 1 사이의 값을 출력하며 Sigmoid보다 학습속도가 빠름
- 인공신경망은 입력층, 은닉층, 출력층의 세 가지 층으로 구성됨
  - 입력층은 예측을 위한 데이터를 입력받는다.
  - 은닉층은 입력층으로부터 전달받은 값을 이용하여 가중 합과 편향을 계산하고, 활성 함수에 적용하여 결과를 산출함
  - 출력층은 활성 함수의 결과를 담고 있으며, 출력 범주의 수가 같도록 구성됨
- 역전파 알고리즘 : 인공신경망을 학습시키기 위한 일반적인 알고리즘. 출력값으로 결정된 결과값의 오차를 역으로 입력층으로 전파하면서 오차가 최소가 될 수 있도록 가중하는 과정. 입력층에서 차례대로 가중치를 계산하는 것보다 빠르고 정확함
- 인공신경망의 종류
  - 단층 퍼셉트론 : AND, OR 연산이 가능하지만, XOR은 선형 분리할 수 없는 문제점이 있음
  - 다층 퍼셉트론 : 입력층과 출력층 사이에 하나 이상의 은닉층을 추가해 비선형 데이터에 대해 학습할 수 있도록 한 퍼셉트론 구조. 은닉층을 가지며 역전파 알고리즘을 통해 다층으로 만들어졌고, 활성화 함수로 시그모이드를 사용한다.
    - 문제점으로 과적합과 기울기 소실이라는 문제점을 가진다.
- 장점 : 스스로 가중치를 학습하여 다양하고 많은 데이터에 효과적임. 패턴인식, 분류, 예측에 효과적임, 비선형 문제 해결
- 단점 : 복잡한 모형일수록 학습 시간이 오래걸림, 추정한 가중치의 신뢰도가 낮음, 결과 해석의 어려움, 은닉층와 은닉 노드 수 결정이 어려움


#### 서포트 벡터 머신(SVM : Support Vector Machine)
- 데이터를 분리하는 초평면 층에서 데이터들과 가장 거리가 먼 초평면을 분리하는 지도 학습 기반의 이진 선형 분류 모델
- 사물 인식, 패턴 인식, 손글시 숫자 인식 등의 다양한 분야에서 활용됨
- 비확률적 선형 판별에 기초한 이진 분류기
- 특징
  - 공간상에서 최적의 분리 초평면을 찾아 분류와 회귀를 수행함
  - 변수 속성 간의 의존성을 고려하지 않으며, 모든 속성을 활용함
  - 훈련 시간이 느린 편이지만, 정확성이 높고 과적합 가능성이 작다.
- 종류
  - 하드 마진 SVM : 마진의 안쪽이나 바깥쪽에 잘못 분류된 오분류를 절대 허용하지 않음
  - 소프트 마진 SVM : 잘못 분류된 오분류를 허용함
- 구성요소
  - 결정경계 : 데이터 분류의 기준이 되는 경계
  - 초평면 : n파원 공간의 (n-1) 차원 평면
  - 마진 : 결정경계에서 서포트벡터까지의 거리
  - 서포트벡터 : 결정경계와 가장 가까이에 있는 학습 데이터들의 집합
  - 슬랙 변수 : 완벽한 분리가 불가능할 때 허용된 오차를 위한 변수
- 커널 트릭 : 선형 분류가 불가능한 데이터를 처리하기 위해 데이터의 차원을 증가시켜 하나의 초평면을 분리가 가능하도록 도와주는 커널 함수를 사용하는 것


#### 연관성 분석
- 데이터에 존재하는 항목 간 상호 관계와 종속관계를 찾아내는 분석 기법
- 장바구니 분석, 서열 분석이라고도 함. 콘텐츠 기반 추천의 기본 기법
- 특징
  - 목적 변수가 없어 분석 방향과 목적이 없어도 적용할 수 있음
  - 조건 반응으로 표현되어 결과를 해석하기 쉬움
  - 너무 세분된 품목은 의미없는 결과를 도출할 수 있음
- 주요 용어
  - 지지도 : 전체 거래 중 항목 A와 B를 동시에 포함하는 거래의 비율
  - 신뢰도 : A 상품을 샀을 때 상품을 살 조건부 확률에 대한 척도
  - 향상도 : 규칙이 우연에 의해 발생한 것인지를 판단하기 위해 연관성의 정도를 측정하는 척도


#### 군집 분석
- 관측된 여러 개의 변수 값에서 유사성에만 기초하여 n개의 군집으로 집단화한 뒤, 그 집단의 특성을 분석하는 다변량 분석 기법
- 계층적 군집
  - 유사한 개체를 군집화하는 과정을 반복하여 군집을 형성한 것
  - 병합적 방법 : 작은 군집으로부터 시작하여 군집을 병합.
  - 분할적 방법 : 큰 군집에서 군집을 분리해나가는 과정
- 계층도(덴드로그램) : 군집의 결과를 보여주는 그림. 각 개체는 단 하나의 군집에만 속함
- 군집간 거리 측정 방법
  - 최단연결법 : 각 군집에서 하나씩 관측값을 뽑았을 때 나올 수 있는 최솟값을 두 군집 사이의 거리로 측정
  - 최장연결법 : 각 군집에서 하나씩 관측값을 뽑았을 때 나올 수 있는 최댓값을 두 군집 사이의 거리로 측정
  - 중심연결법 : 두 군집 중심 간의 거리를 측정
  - 평균연결법 : 모든 항목에 대한 거리 평균
  - 와드연결법 : 군집 내의 오차 제곱합에 기초하여 군집을 수행
- 군집간 거리 계산 방법
  - 유클리드 거리 : 두 점 간 차를 제곱하여 모두 더한 값
  - 맨해튼 거리 : 두 점 간 차의 절대값을 합한 값
  - 민코프스키 거리 : m차원 민코프스키 공간에서의 거리(1일 경우 맨해튼, 2일 경우 유클리드)
  - 표준화 거리 : 변수의 측정단위를 표준화한 거리
  - 마할라노비스 거리 : 변수의 표준화와 함께 변수 간의 상관성을 동시에 고려한 통계적 거리


#### 군집 분석-K 평균 군집
- 주어진 데이터를 k개의 군집으로 묶는 알고리즘. 초기 값으로 k개의 군집으로 지정하고, 각 개체를 가까운 초기 값에 할당하여 군집을 형성함
- 절차
  1. 군집의 수 k를 임의로 선택
  2. 데이터를 가장 가까운 군집 중심에 할당
  3. 각 군집 내의 자료들의 평균을 계산하여 군집의 중심을 갱신
  4. 군집 중심의 변화가 거의 없을 때까지 단계 2와 단계 3을 반복 진행


#### 군집 분석-혼합 분포 군집
- 데이터가 k개의 모수적 모형의 가중 합으로 표현되는 모집단 모형으로부터 나왔다는 가정하에 자료로부터 모수와 가중치를 추정하는 방법
- k개의 각 모형은 군집을 의미하며, 각 데이터는 k개의 군집 중 어느 군집에서 나왔을 확률이 높은지에 따라 군집의 분류가 이루어진다.
- EM 알고리즘
  - 관측되지 않은 잠재변수에 의존하는 확률뫄델에서 최대 가능도나 최대 사후 확률을 갖는 모수의 추정값을 찾는 반복적인 알고리즘
  - E 단계와 M 단계로 나누어 진행함
  - E 단계에서 잠재변수 Z의 기대치를 계산하고 M 단계에서 기대치를 활용하여 파라미터를 추정함
- 특징
  - 확률 분포를 도입하여 군집을 수행함
  - 군집을 몇 개의 모수로 표현할 수 있고, 서로 다른 크기의 군집을 찾을 수 있다.
  - EM 알고리즘을 활용한 모수 추정에서 데이터가 커지면 시간이 오래 걸린다.
  - 군집이 너무 작으면 추정이 어려워짐
  - 이상치에 민감하여 사전에 이상치를 제거하는 작업이 필요함


#### 군집 분석-자기 조직화 지도(SOM : Self-Organizing Maps)
- 인공신경망 개념. 자율 학습 방법에 따른 군집화를 적용한 알고리즘
- 고차원의 데이터를 저차원의 뉴런으로 정렬하여 지도의 형태로 형상화하는 비지도 신경망
- 구성
  - 입력층 : 입력 벡터를 받는 층. 입력변수의 개수와 같은 뉴런이 존재
  - 경쟁층 : 각각의 뉴런이 입력 벡터와 얼마나 가까운지 계산하여 연결 강도를 재조정 학습
- 알고리즘
  1. SOM 맵의 노드에 대한 연결 강도 초기화
  2. 입력 벡터 제시
  3. 유클리드 거리를 사용하여 입력 벡터와 프로토타입 벡터의 유사도를 계산
  4. 입력 벡터와 가장 거리가 짧은 프로토타입 벡터 탐색
  5. BMU와 그 이웃들의 연결 강도 재조정. 이후 단계 2로 가 반복


#### 고급 분석 기법-범주형 자료 분석
- 범주 또는 집단으로 나누어진 자료. 범주형 자료의 순서가 없으면 명목형 자료, 순서가 있으면 순서형 자료라고 함

|독립변수|종속변수|분석 방법|
|----|----|----|
|범주형|연속형|t-검정, 분산분석(ANOVA)|
|범주형|범주형|분할표 분석, 카이제곱 검정, 피셔의 정확도 검정|
|연속형|범주형|로지스틱 회귀분석|


#### t-검정
- 두 집단 간의 평균을 비교하는 모수적 통계방법. t분포를 이용해 가설을 검정하며 정규성, 등분산성, 독립성을 가정한다.
- 단일표본, 독립표본, 대응표본에 대한 검정을 수행함
  - 단일표본 검정 : 표본의 평균으로 모집단의 평균을 검정
  - 독립표본 검정 : 서로 다른 두 집단의 평균의 차이를 검정
  - 대응표본 검정 : 동일한 집단의 사전 사후 차이를 검정


#### 분산분석(ANOVA : Analysis of Variance)
- 둘 이상의 집단의 평균을 비교하는 모수적 통계방법. F분포를 이용해 가설을 검정하며 정규성, 등분산성, 독립성을 가정함
- 일원분산분석(one-way ANOVA) : 범주형 변수가 한 개인 경우 사용
  - 귀무가설 : 모든 집단의 평균이 같다. / 대립가설 : 하나 이상의 집단 평균이 다르다.
- 이원분산분석(two-way ANOVA) : 범주형 변수가 두 개 이상인 경우 두 변수의 상호작용효과와 각 변수의 주효과를 분석함
  - 귀무가설 : 두 변수는 상호작용효과가 없다 / 대립가설 : 두 변수는 상호작용효과가 있다.


#### 분할표 분석
- 두 범주형 변수의 빈도 분포표를 작성할여 변수 간 상호 관련성을 분석하는 방법
- 상대위험도(RR : Relative Risk) : 두 집단이 사건발생 확률의 비
- 승산비(OR : Odds Ratio) : 특정 집단에 대한 사건발생 확률과 사건이 발생할지 않을 확률의 비
- 교차비(OR) : odds(A)/odds(B)=ad/bc

|상대위험도|교차비|해석|
|----|----|----|
|RR<1|OR<1|A 집단의 사건 발생 확률이 낮음|
|RR=1|OR=1|집단과 사건 발생 확률은 연관성이 없음|
|RR>1|OR>1|A 집단의 사건 발생확률이 높음|
- 활용 : 집단에 따라 사건 발생 가능성을 확인하는 방법
  - 코호트 연구 : 특정 집단을 대상으로 선정하고 장기간의 추적을 통해 미리 조사한 위험인자들과 질병 발생 간의 연관성을 연구
  - 환자-대조군 연구 : 질병이 있는 환자군과 없는 대조군을 따로 선정하고 위험인자를 나중에 조사함


#### 카이제곱 검정
- 범주형 자료 간의 차이를 분석하는 모수적 통계방법. x^2 분포를 이용하여 적합성 검정, 독립성 검정, 동질성 검정으로 나뉨
- 적합도 검정 : 하나의 범주형 변수에 대하여 데이터가 특정 분포를 만족하는지 검정함
  - 귀무가설 : 분포가 기대 분포와 같다. / 대립가설 : 분포가 기대 분포와 같지 않다.
- 동질성 검정 : 서로 다른 집단에 대한 범주형 변수의 분포가 동질인지 검정한다.
  - 귀무가설 : 두 집단의 분포가 같다. / 대립가설 : 두 집단의 분포가 같지 않다.
- 독립성 검정 : 두 범주형 변수가 서로 독립적인지 영향을 미치는지 검정한다.
  - 귀무가설 : 두 변수는 연관성이 없다. / 대립가설 : 두 변수는 연관성이 있다.


#### 피셔의 정확 검정(Fisher's Exact Test)
- 가능한 모든 경우의 수를 직접 확인하는 검정 방법. 초기하 분포를 기반으로 함.
- 가설은 카이제곱 검정과 동일하며, 기대빈도가 5보다 작은 셀이 20%를 넘으면 카이제곱 검정보다 피셔의 정확 검정을 사용함
- ex: 분할표에서 표본의 수가 작거나 범주가 많아서 빈도수가 극도로 작은 경우 사용한다.


#### 고급 분석 기법-다변량 분석
- 여러 변수를 동시에 분석할 수 있는 모든 분석 방법을 가리킴
- 각 변수를 개별적으로 분석하지 않고 변수 간으 상관관계를 고려한다

#### 상관관계분석
- 변수들 간의 상관성을 분석한다.
- 피어슨 상관계수 : 두 변수의 공분산을 표준편차의 곱으로 나눈 값. 비선형 관계는 측정하지 못함
- 스피어만 상관계수 : 두 변수를 순위로 변환하여 순위의 상관계수로 비선형적인 관계를 나타낼 수 있음


#### 다차원 척도법(MDS : Multidimensional Scaling)
- 차원 축소를 통해 개체들 간의 관계를 상대적 위치로 시각화하여 나타내는 분석 방법.
- 데이터가 연속형 변수인 경우 거리 행렬을 이용한 다차원 척도법을 사용한다.
- 데이터가 순서형 척도인 경우 순서척도를 거리로 변환하는 비계량적 다차원 척도법을 사용한다 
- 적용 절차
  1. 유클리드 거리행렬 등을 활용해 개체들 간의 유사성을 측정한다.
  2. 2차원 또는 3차원 공간에 개체를 점으로 배열한다 
  3. 스트레스 값을 부적합도로 측정하여 최소가 되도록 좌표를 조정한다.
    - 0-0.1 : 매우 좋음, 0.1-0.2 : 좋음, 0.2 이상 : 나쁨


#### 다변량 분산분석(MAMOVA : Multivariate Analysis of Variance)
- 2개 이상의 종속변수에 대한 분산분석 방법. 범주형 독립변수에 대한 평균벡터 차이를 분석함
- 종속변수 간에 서로 상관관계가 있는 경우 결합된 차이를 확인할 수 있다.
- 상관관계가 없는 경우 개별로 분산분석을 수행해야 한다. 정규성, 등분산성, 독립성을 가정한다.
  - 귀무가설 : 모든 집단의 평균벡터가 같다. / 대립가설 : 하나 이상의 집단의 평균벡터가 다르다


#### 주성분분석(PCA : Principal Component Analysis)
- 데이터 전체의 변동을 최대한 보존하는 주성분을 생성하는 차원축소 방법
- 주성분 : 데이터의 분산을 설명하는 설명변수들의 선형 결합으로 표현된다. 항상 설명변수와 동일한 수만큼 성분을 추출할 수 있다. 상관성이 적은 주성분을 활용하여 회귀분석의 다중공선성 문제를 해결할 수 있다.
- 누적 기여율(Cumulative Proportion) : 주성분을 고유값의 내림차순으로 정렬하여 상위 n개의 주성분으로 설명할 수 있는 정보량의 비율


#### 요인분석(FA : Factor Analysis)
- 변수들의 상관관계를 기반으로 공통의 요인을 찾아 데이터를 요약하고 차원을 축소하는 분석 방법
- 연역적 방법인 확인적 요인분석(CFA)와 귀납적 방법인 탐색적 요인분석(EFA)이 있다.
- 요인 추출 방법 : 주성분 분석과 공통요인법(Common Factor Analysis)이 많이 사용된다. 요인 수를 최소화하는 경우 주성분 분석을 선택한다.
- 요인 회전 방법 : 베리맥스, 쿼티멕스, 이쿼멕스 등의 직각회전 방법과 오블리민 등의 사각 회전으로 나뉜다. 베리멕스 방법을 주로 사용한다.

#### 주성분분석과 요인분석의 비교
- 공통점 : 차원 축소 기능, 다른 분석을 위한 사전 분석
- 차이점
  - PCA :선형적 결합 중심, 데이터를 요약하는 주성분을 추출함, 주성분간 중요도 차이 있음
  - FA : 잠재적 결합 중심, 상관성 기준 잠재 변수를 생성함, 새로운 변수들은 서로 대등함


#### 판별분석(Discriminant Function Analysis)
- 연속형 독립변수들의 선형조합을 통해 집단을 분류하고 예측하는 분석 방법
- 오분류율이 최소가 되는 판별함수를 도출하고 판별 능력을 평가.
- 독립변수의 정규성, 등분산성을 가정함
- 판별함수 : 분류를 위한 기준으로 판별점수를 산출한다.
- 판별함수의 수=Min(집단의 수-1, 독립변수의 수)

#### 고급 분석 기법-시계열 분석
- 시계열 데이터는 시간의 영향을 받는 데이터다. 시계열 데이터는 일정한 시간 간격을 두고 관측되므로 시차가 동일하며 이론적으로 결측값이 없다.
- 정상성(Stationary) : 시점에 상관없이 일정한 시계열 데이터의 특성을 의미함. 대부분 시계열 자료는 정상성을 만족하지 않는 비정상 시계열이다. 이에 따라 아래의 조건을 만족하는 정상 시계열로 정상화하여 분석을 수행한다.
  - 평균이 시점에 의존하지 않는다. 즉, 모든 시점의 평균이 동일하다.
  - 분산이 시점에 의존하지 않는다. 즉, 모든 시점의 분산이 동일하다.
  - 공분산은 시차에만 의존하고 시점에는 의존하지 않는다. 즉, 시차가 같으면 공분산은 동일하다.
- 비정상성 확인
  - 자기상관함수(ACF : Autocorrelation Function) : 자체 시계열 데이터간의 선형 상관관계 함수.
  - 부분자기상관함수(PACF : Partial Autocorrelation Function) : 두 시점 사이에 영향을 주는 다른 요인을 제외한 자기상관함수
- 비정상 시계열의 정상화
  - 이상치가 있는 경우 이상치를 제거하거나 대체해 정상화함
  - 평균이 일정하지 않은 경우 차분(Difference)을 통해 정상화함
  - 분산이 일정하지 않은 경우 변환(Transformation)을 통해 정상화함