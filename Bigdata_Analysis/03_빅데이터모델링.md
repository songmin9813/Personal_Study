# 3. 빅데이터 모델링
## 1. 분석 모형 설계
#### 분석 방법
- **통계 분석**(Statistical analysis) : 특정 집단이나 불확실한 현상을 데이터를 통해 이해하고 추론을 통해 의사결정하는 과정
  - 기술 통계 : 데이터를 요약/정리하고 이해하기 위해 평균, 표준편차 등 기초통계량을 구하거나 그래프로 표현하는 분석방식
  - 추론 통계 : 수집된 데이터를 기반으로 모집단에 대해 추정하고 가설을 검정하는 분석 방법
- **데이터 마이닝**(Data Mining) : 데이터에 숨어있는 유용한 정보를 찾아내는 과정. 분류 분석, 추정 분석, 예측 분석, 연관 분석, 군집 분석, 기술 분석 등이 존재
- **머신 러닝**(Machine Learning) : 분석 모형 알고리즘이 데이터를 학습하고 학습한 정보를 바탕으로 결과를 출력하는 분석방법. 종속변수의 존재 여부, 학습 방법 등에 따라 지도 학습, 비지도 학습, 강화학습으로 구분함
  - **지도 학습**(Supervised Learning) : 정답에 해당하는 종속변수가 포함되어 있는 데이터를 학습. 종속변수와 독립변수 간의 관계를 분석하여 분류, 예측 등의 문제를 해결함. 종속변수가 연속형인 경우 수치 예측, 범주형인 경우 분류 예측을 시행한다.
    - **지도 학습의 종류** : 회귀 분석, 로지스틱 회귀분석, 나이브 베이즈, KNN, 의사결정나무, 인공신경망, SVM, 랜덤포레스트
  - **비지도 학습**(Unsupervised Learning) : 종속변수가 포함되지 않는 데이터를 학습. 예측 문제보다는 현상 설명, 특징 도출, 패턴 도출 등의 문제를 해결한다.
    - **비지도 학습의 종류** : 군집화(K-means, SOM, 계층군집), 차원 축소(주성분분석, 선형판별분석), 연관분석, 자율학습 인공신경망


#### 데이터 유형에 따른 모형 구분
|데이터 유형|연속형 종속변수|범주형 종속변수|종속변수 없음|
|----|----|----|--------|
|연속형 독립변수|회귀분석 트리 모형,인공신경망,SVR,KNN|로지스틱 회귀분석 트리 모형, 인공신경망, SVM, KNN|주성분 분석, 군집 분석|
|범주형 독립변수|회귀분석, t-test, ANOVA, 트리 모형, 인공신경망|로지스틱 회귀분석, 카이제곱 검정, 트리 모형, 인공신경망, 나이브베이즈|연관 분석, 판별분석|
|연속형+범주형 독립변수|회귀분석, 트리 모형, 인공신경망|트리 모형, 인공신경망|상관 분석|


#### 변수 선택
- 전진 선택법 : 상관관계가 큰 변수부터 순차적으로 모형에 추가하며 변수를 추가하는 방법
- 후진 제거법 : 모든 독립변수를 추가한 모형에서 상관관계가 작은 변수부터 순차적으로 제거하는 방법
- 단계적 선택법 : 전진 선택법으로 순차적으로 변수를 추가하면서 중요도가 약해진 변수를 후진 제거법으로 제거하는 방법


#### 파라미터와 하이퍼 파라미터
- 파라미터 : 모형 내부 요소로 모형의 성능에 직접적인 영향을 미친다. 모형이 데이터를 학습한 결과 값으로 자동으로 결정된다.
- **하이퍼 파라미터** : 모형 외부 요소로 모형의 성능에 간접적인 영향을 미친다. 사용자가 설정하는 값으로 학습 과정에 영향을 주고 학습 결과인 파라미터 값에 영향을 준다.
- 하이퍼 파라미터 튜닝 방법
  - **매뉴얼 서치**(Manual Search) : 사용자가 직감 또는 경험에 근거하여 직접 하이퍼 파라미터를 조합하고 조정하는 방법. 매우 비효율적인 방법
  - **그리드 서치**(Grid Search) : 가능한 모든 조합을 시도하여 최적의 파라미터 값을 찾는 방법. 후보를 직접 선정하므로 후보 내에서 가장 좋은 결과를 얻을 수 있으나 후보가 아닌 값은 시도하지 않는다.
  - **랜덤 서치**(Random Search) : 하이퍼 파라미터의 값 범위를 지정하고 무작위 표본추출을 통해 생성한 조합을 시도하여 최적의 파라미터 값을 찾는 방법. 그리드 서치와 거의 동일하나 그리드 서치의 단점을 보완한다. **난수를 통해 확률적으로 탐색하므로 불필요한 값의 중복을 없앤다는 특징**을 가진다.


#### 데이터 분할
- **홀드아웃**(Hold-Out) : 가장 보편적인 방법으로 랜덤 추출을 통해 데이터를 분할함. 일반적으로 학습 데이터와 검증 데이터를 60-80%, 테스트 데이터를 20-40%로 분할한다.
- **K-fold 교차 검증** : 테스트 데이터를 제외한 데이터를 무작위로 중복되지 않는 K개의 데이터로 분할한다. (K-1)개의 데이터를 학습 데이터로 사용하고 나머지 1개 데이터를 검증 데이터로 사용한다. 이후 검증 데이터를 바꾸며 K번 반복하여 분할된 데이터가 한 번씩 검증 데이터로 사용된다.
- **부트스트랩**(Bootstrap) : 데이터의 분포가 치우쳐 있거나 데이터 건수가 너무 적을 때 사용 가능한 기법이다. 복원 추출을 통해 전체 데이터와 동일한 사이즈의 샘플 데이터를 추출한다. 어떤 데이터는 부트스트랩 샘플에 한 번 이상 포함되나 어떤 데이터는 한 번도 포함되지 않을 수 있다. 데이터의 사이즈가 충분히 크다면 전체 데이터의 약 63.2%를 포함한다.
- 데이터가 부족한 경우 검증용 데이터는 분할하지 않기도 한다.


#### 분석 모형 구축의 절차
- 요건 정의-모델링-검증 및 테스트-적용 단계로 구성
1. **요건 정의** : 기획 단계에서 도출한 내용을 요건 정의로 구체화하는 단계. **요구사항 도출-분석 추진 계획 수립-요구사항 확정**으로 이루어짐
2. **모델링** : 정의된 요건에 따라 본격적인 분석을 수행하는 단계. 데이터 준비 및 탐색적 데이터 분석을 수행하고 모델링과 성능 평가를 반복 수행하여 최종 모형을 선정한다. **데이터 마트 설계 및 구축-탐색적 분석 및 유의변수 도출-모델링-모델 성능 평가**로 이루어짐
3. **검증 및 테스트** : 분석 모형을 가상 운영 환경에서 테스트하는 단계. **운영 환경 테스트-비즈니스 영향도 평가**로 이루어짐
4. **적용** : 분석 결과를 실제 운영 환경에 적용하는 단계. **운영 시스템 적용-주기적 모델 업데이트**로 이루어짐


## 2. 분석 기법 적용
#### 회귀분석의 가정
- 선형성 : 독립변수와 종속변수는 선형적. 종속변수는 독립변수와 회귀계수의 선형적 조합으로 표현 가능. 산점도를 통해 선형성을 확인 가능
- 독립성 : 단순 회귀분석에는 잔차와 독립변수의 값이 서로 독립. 다중 회귀분석에서는 독립변수 간에 상관성 없이 독립
- 등분산성 : 잔차의 분산이 독립변수와 무관하게 일정. 잔차가 고르게 분포해야 함
- 정규성 : 잔차항이 정규분포의 형태를 띰. 잔차항의 평균은 0이고 분산이 일정함.

회귀분석의 위의 네 가정을 만족하는 데이터의 경우에 사용한다.


#### 회귀분석의 종류
- 단순 회귀 : 독립변수가 1개이며 종속변수와의 관계가 직선
- 다중 회귀 : 독립변수가 k개이며 종속변수와의 관계가 선형
- 다항 회귀 : 독립변수와 종속변수와의 관계가 1차 함수 이상인 관계
- 곡선 회귀 : 독립변수가 1개이며, 종속변수와의 관계가 곡선
- 비선형 회귀 : 회귀식의 모양이 미지의 모수들의 선형관계로 이뤄져있지 않은 모형


#### 단순선형 회귀분석
- 독립변수와 종속변수가 한 개씩 있으며 오차항이 있는 선형관계로 이뤄진다.(직선관계)
- 회귀계수는 최소제곱법을 사용하여 추정한다.
- 결정계수(R의 제곱)는 회귀 모형의 설명력을 보여주는 지표이며 회귀선의 정확도를 평가한다.
  - R의 제곱=회귀제곱합/전체제곱합


#### 다중선형 회귀분석
- 독립변수가 k개인 경우. 독립변수와 종속변수와의 관계는 1차 함수 이상인 경우이며 선형이다.
- 모형의 통계적 유의성은 F-통계량으로 확인하며, p-value가 0.05보다 작으면 회귀식이 통계적으로 유의하다고 본다.
- 다중선형 회귀분석의 검정
  - 회귀계수의 유의성 : 회귀계수의 유의성은 t-통계량을 통해 확인
  - 결정계수(R제곱) : 회귀 모형의 설명력을 보여주는 지표
  - 모형의 적합성 : 잔차와 종속변수의 산점도로 확인
  - 다중공선성 : 설명 변수들 사이에 선형관계가 존재하여 회귀계수의 추정에 부정적인 영향을 미치는 것을 의미


#### 규제가 있는 회귀 분석
- 릿지 회귀(Lidge)
  - 높은 상관관계가 있는 변수 간 검청 오차(또는 검정 MSE)가 최소인 모델을 찾는 것을 목적으로 가진다.
  - 규제항을 비용 함수에 추가하며, 모델의 훈련이 끝나면 모델의 성능을 규제 없는 성능 지표로 평가한다.
  - 알파는 모델을 얼마나 많이 규제할지 조절하는 것으로, 값이 커질수록 모든 가중치가 0에 수렴한다.
  - L2 규제 : 모든 파라미터 제곱만큼의 크기를 규제하는 방식. 가중치를 제약하여 가중치 값을 널리 퍼지도록 하는 효과를 준다.

- 라쏘 회귀(Lasso)
  - 변수 선택을 통해 변수 간 검정오차(또는 검정 MSE)가 최소인 모델을 찾는 것을 목적으로 가진다.
  - 릿지와 마찬가지로 규제항을 추가하지만 제곱이 아닌 절댓값을 적용한 값임
  - 알파의 값이 설정되면 중요하지 않은 변수들의 가중치가 0이 되어 제거되기에 해당 변수가 없는 것과 마찬가지가 된다.
  - L1 규제 : 가중치 벡터를 0으로 규제하는 방식. 의미있는 변수만을 선택하는 효과를 준다.
  - 다중공선성이 있는 경우에는 다중공선성이 발생하는 변수 그룹의 모든 변수가 제거되는 경우가 발생할 수 있어 릿지 회귀보다 성능이 떨어질 수 있다. 

- 엘라스틱넷 회귀(Elastic Net)
  - 릿지와 라쏘 회귀의 절충안. 두 회귀의 규제항을 단순히 더하여 사용하며 혼합 비율을 조절하여 어느 방식의 비중을 크기 할 것인지 결정한다.


#### 로지스틱 회귀분석
- 독립변수의 선형결합을 이용해 사건의 발생 여부를 예측하며, 종속변수가 범주형일 경우에 사용하는 회귀분석
- 종속변수의 범주가 두 개일 때 이항 로지스틱 회귀분석이라 하고, 그 이상이면 다항 로지스틱 회귀분석이라 함
- 일반적인 선형 회귀분석은 x값과 y값 모두 연속적인 값을 가진다. 하지만 로지스틱 회귀분석의 경우,  y값을 0~1(확률 P) 사이의 값을 갖게 하고 두 가지고 분류하려고 하는 과정이므로 수식을 변환하는 과정이 필요하다.
- 선형 회귀분석은 정규분포를 따르지만, 로지스틱 회귀분석은 이항분포를 따른다는 차이점이 있다.
- 모형 적합성
  - 모형의 유의성 : 모형이 설명하지 못하는 데이터의 정도를 의미하는 Deviance(이탈도)를 통해 검증. 이탈도가 적을수록 유리함
  - 계수의 유의성 : 왈드(ward) 검정을 통해 독립변수가 종속변수에 미치는 영향 확인. 검정 통계량인 z-value의 p-value가 유의수준보다 작으면 계수가 유의함
  - 모형의 설명력 : 로지스틱 회귀분석은 보통 결정계수가 낮게 나오는 편이므로, McFadden이 제안한 의사결정계수를 사용하는 것이 일반적임. AIC값이 작을수록 설명력이 좋음


#### 의사결정나무 분석
- 과거에 수집된 자료를 분석해서 이들 사이에 존재하는 패턴을 나타내는 분류모형을 나무모형으로 나타낸 것. 전체 자료를 여러 개의 소집단으로 분류하거나 예측하는 데 사용되는 기법
- 분석 과정
  - 의사결정 나무의 성장 : 데이터의 구조에 따라 분리 기준과 정지 규칙을 설정한다.
  - 정지 규칙 : 더 이상 트리가 분리되지 않도록 하는 규칙을 설정한다.
  - 가지치기 : 불필요한 가지를 제거하여 모형의 복잡도를 줄이는 과정
- 장점
  - 해석의 용이성 : 나무 구조로 표현되어 사용자의 이해가 쉬움
  - 상호작용 효과의 해석 가능 : 두 개 이상의 변수의 영향 정도를 쉽게 파악
  - 비모수적 모형 : 선형성, 정규성, 등분산성 등의 가정을 필요로 하지 않는 비모수적인 방법. 이상값에 민감하지 않음
  - 유연성, 정확도 높음 : 대용량 데이터에서도 빠르게 생성할 수 있다.
- 단점
  - 비연속성 : 연속형 변수를 비연속적 값으로 취급하여 분리 경계점에서는 예측오류가 커짐
  - 선형성 결여 : 각 변수의 고유한 영향력을 해석하기 어려움
  - 비안정성 : 학습용 자료에 의존하여 과대 적합 발생 가능성이 높음



#### 인공신경망 분석
- 사람 두뇌의 신경세포인 뉴런이 전기신호를 전달하는 모습을 모방한 기계학습 모델. 간단한 계산능력을 가진 처리 단위인 뉴런/노드들이 복잡하게 연결된 구조를 이루고 있으며, 입력데이터를 기초로 가중치를 통해 의사결정을 함
- 인공신경망의 구조
  - 활성 함수 : 노드에 입력된 값을 비선형 함수에 통과시켜 다음 노드로 전달하는데, 이 비선형 함수를 활성 함수라 함
    - Sigmoid 함수 : 로지스틱 함수라고도 함. 곡선의 형태로 0과 1사이의 값을 출력. 은닉층을 거칠 때마다 값이 0으로 수렴하는 문제를 가짐
    - ReLU 함수 : 입력값이 0보다 작으면 0을, 0보다 크면 입력값을 그대로 출력하는 함수. 연산이 빠르지만 0보다 작은 값에 대해 뉴런이 작동하지 않을 수 있음
    - Tanh 함수 : Sigmoid의 확장 형태. -1과 1 사이의 값을 출력하며 Sigmoid보다 학습속도가 빠름
- 인공신경망은 입력층, 은닉층, 출력층의 세 가지 층으로 구성됨
  - 입력층은 예측을 위한 데이터를 입력받는다.
  - 은닉층은 입력층으로부터 전달받은 값을 이용하여 가중 합과 편향을 계산하고, 활성 함수에 적용하여 결과를 산출함
  - 출력층은 활성 함수의 결과를 담고 있으며, 출력 범주의 수가 같도록 구성됨
- 역전파 알고리즘 : 인공신경망을 학습시키기 위한 일반적인 알고리즘. 출력값으로 결정된 결과값의 오차를 역으로 입력층으로 전파하면서 오차가 최소가 될 수 있도록 가중하는 과정. 입력층에서 차례대로 가중치를 계산하는 것보다 빠르고 정확함
- 인공신경망의 종류
  - 단층 퍼셉트론 : AND, OR 연산이 가능하지만, XOR은 선형 분리할 수 없는 문제점이 있음
  - 다층 퍼셉트론 : 입력층과 출력층 사이에 하나 이상의 은닉층을 추가해 비선형 데이터에 대해 학습할 수 있도록 한 퍼셉트론 구조. 은닉층을 가지며 역전파 알고리즘을 통해 다층으로 만들어졌고, 활성화 함수로 시그모이드를 사용한다.
    - 문제점으로 과적합과 기울기 소실이라는 문제점을 가진다.
- 장점 : 스스로 가중치를 학습하여 다양하고 많은 데이터에 효과적임. 패턴인식, 분류, 예측에 효과적임, 비선형 문제 해결
- 단점 : 복잡한 모형일수록 학습 시간이 오래걸림, 추정한 가중치의 신뢰도가 낮음, 결과 해석의 어려움, 은닉층와 은닉 노드 수 결정이 어려움