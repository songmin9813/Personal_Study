# 3. 빅데이터 모델링
## 1. 분석 모형 설계
#### 분석 방법
- **통계 분석**(Statistical analysis) : 특정 집단이나 불확실한 현상을 데이터를 통해 이해하고 추론을 통해 의사결정하는 과정
  - 기술 통계 : 데이터를 요약/정리하고 이해하기 위해 평균, 표준편차 등 기초통계량을 구하거나 그래프로 표현하는 분석방식
  - 추론 통계 : 수집된 데이터를 기반으로 모집단에 대해 추정하고 가설을 검정하는 분석 방법
- **데이터 마이닝**(Data Mining) : 데이터에 숨어있는 유용한 정보를 찾아내는 과정. 분류 분석, 추정 분석, 예측 분석, 연관 분석, 군집 분석, 기술 분석 등이 존재
- **머신 러닝**(Machine Learning) : 분석 모형 알고리즘이 데이터를 학습하고 학습한 정보를 바탕으로 결과를 출력하는 분석방법. 종속변수의 존재 여부, 학습 방법 등에 따라 지도 학습, 비지도 학습, 강화학습으로 구분함
  - **지도 학습**(Supervised Learning) : 정답에 해당하는 종속변수가 포함되어 있는 데이터를 학습. 종속변수와 독립변수 간의 관계를 분석하여 분류, 예측 등의 문제를 해결함. 종속변수가 연속형인 경우 수치 예측, 범주형인 경우 분류 예측을 시행한다.
    - **지도 학습의 종류** : 회귀 분석, 로지스틱 회귀분석, 나이브 베이즈, KNN, 의사결정나무, 인공신경망, SVM, 랜덤포레스트
  - **비지도 학습**(Unsupervised Learning) : 종속변수가 포함되지 않는 데이터를 학습. 예측 문제보다는 현상 설명, 특징 도출, 패턴 도출 등의 문제를 해결한다.
    - **비지도 학습의 종류** : 군집화(K-means, SOM, 계층군집), 차원 축소(주성분분석, 선형판별분석), 연관분석, 자율학습 인공신경망


#### 데이터 유형에 따른 모형 구분
|데이터 유형|연속형 종속변수|범주형 종속변수|종속변수 없음|
|----|----|----|--------|
|연속형 독립변수|회귀분석 트리 모형,인공신경망,SVR,KNN|로지스틱 회귀분석 트리 모형, 인공신경망, SVM, KNN|주성분 분석, 군집 분석|
|범주형 독립변수|회귀분석, t-test, ANOVA, 트리 모형, 인공신경망|로지스틱 회귀분석, 카이제곱 검정, 트리 모형, 인공신경망, 나이브베이즈|연관 분석, 판별분석|
|연속형+범주형 독립변수|회귀분석, 트리 모형, 인공신경망|트리 모형, 인공신경망|상관 분석|


#### 변수 선택
- 전진 선택법 : 상관관계가 큰 변수부터 순차적으로 모형에 추가하며 변수를 추가하는 방법
- 후진 제거법 : 모든 독립변수를 추가한 모형에서 상관관계가 작은 변수부터 순차적으로 제거하는 방법
- 단계적 선택법 : 전진 선택법으로 순차적으로 변수를 추가하면서 중요도가 약해진 변수를 후진 제거법으로 제거하는 방법


#### 파라미터와 하이퍼 파라미터
- 파라미터 : 모형 내부 요소로 모형의 성능에 직접적인 영향을 미친다. 모형이 데이터를 학습한 결과 값으로 자동으로 결정된다.
- **하이퍼 파라미터** : 모형 외부 요소로 모형의 성능에 간접적인 영향을 미친다. 사용자가 설정하는 값으로 학습 과정에 영향을 주고 학습 결과인 파라미터 값에 영향을 준다.
- 하이퍼 파라미터 튜닝 방법
  - **매뉴얼 서치**(Manual Search) : 사용자가 직감 또는 경험에 근거하여 직접 하이퍼 파라미터를 조합하고 조정하는 방법. 매우 비효율적인 방법
  - **그리드 서치**(Grid Search) : 가능한 모든 조합을 시도하여 최적의 파라미터 값을 찾는 방법. 후보를 직접 선정하므로 후보 내에서 가장 좋은 결과를 얻을 수 있으나 후보가 아닌 값은 시도하지 않는다.
  - **랜덤 서치**(Random Search) : 하이퍼 파라미터의 값 범위를 지정하고 무작위 표본추출을 통해 생성한 조합을 시도하여 최적의 파라미터 값을 찾는 방법. 그리드 서치와 거의 동일하나 그리드 서치의 단점을 보완한다. **난수를 통해 확률적으로 탐색하므로 불필요한 값의 중복을 없앤다는 특징**을 가진다.


#### 데이터 분할
- **홀드아웃**(Hold-Out) : 가장 보편적인 방법으로 랜덤 추출을 통해 데이터를 분할함. 일반적으로 학습 데이터와 검증 데이터를 60~80%, 테스트 데이터를 20~40%로 분할한다.
- **K-fold 교차 검증** : 테스트 데이터를 제외한 데이터를 무작위로 중복되지 않는 K개의 데이터로 분할한다. (K-1)개의 데이터를 학습 데이터로 사용하고 나머지 1개 데이터를 검증 데이터로 사용한다. 이후 검증 데이터를 바꾸며 K번 반복하여 분할된 데이터가 한 번씩 검증 데이터로 사용된다.
- **부트스트랩**(Bootstrap) : 데이터의 분포가 치우쳐 있거나 데이터 건수가 너무 적을 때 사용 가능한 기법이다. 복원 추출을 통해 전체 데이터와 동일한 사이즈의 샘플 데이터를 추출한다. 어떤 데이터는 부트스트랩 샘플에 한 번 이상 포함되나 어떤 데이터는 한 번도 포함되지 않을 수 있다. 데이터의 사이즈가 충분히 크다면 전체 데이터의 약 63.2%를 포함한다.
- 데이터가 부족한 경우 검증용 데이터는 분할하지 않기도 한다.


#### 분석 모형 구축의 절차
- 요건 정의-모델링-검증 및 테스트-적용 단계로 구성
1. **요건 정의** : 기획 단계에서 도출한 내용을 요건 정의로 구체화하는 단계. **요구사항 도출-분석 추진 계획 수립-요구사항 확정**으로 이루어짐
2. **모델링** : 정의된 요건에 따라 본격적인 분석을 수행하는 단계. 데이터 준비 및 탐색적 데이터 분석을 수행하고 모델링과 성능 평가를 반복 수행하여 최종 모형을 선정한다. **데이터 마트 설계 및 구축-탐색적 분석 및 유의변수 도출-모델링-모델 성능 평가**로 이루어짐
3. **검증 및 테스트** : 분석 모형을 가상 운영 환경에서 테스트하는 단계. **운영 환경 테스트-비즈니스 영향도 평가**로 이루어짐
4. **적용** : 분석 결과를 실제 운영 환경에 적용하는 단계. **운영 시스템 적용-주기적 모델 업데이트**로 이루어짐