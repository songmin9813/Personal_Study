# 1. 빅데이터 분석 기획
## 1. 빅데이터의 이해
#### DKIW  피라미드
- **데이터(Data)** : 가공되기 전의 객관적 수치 또는 기호
- **정보(Information)** : 데이터의 가공 및 처리를 통해 도출된 현상
- **지식(Knowledge)** : 정보의 구조화를 통해 도출되는 **고유의 아이디어**(개인 아이디어라고 생각)
  - 지식은 그 존재의 형태에 따라 암묵지와 형식지로 나뉜다.
    - 암묵지 : 개인에게 축적된 내면화된 지식 / 형식지 : 언어나 문서로 표준화 및 형상화된 지식으로 표출화
- **지혜(Wisdom)** : 지식의 축적과 아이디어가 결합된 창의적 산물


#### 빅데이터의 특징(5V)
- **규모(Volume)** : 수집, 저장, 처리하는 데이터의 규모가 매우 큼
- **다양성(Variety)** : 정형화된 데이터뿐만 아니라 다양한 유형의 데이터를 처리함
- **속도(Velocity)** : 데이터의 수집, 분석, 활용의 속도가 매우 빠름
- **신뢰성(Veracity)** : 데이터 처리를 통한 노이즈 제거로 수집된 데이터의 신뢰 확보
- **가치(Value)** : 수집된 데이터를 처리함으로 다양한 가치를 창출함


#### 빅데이터가 만들어내는 변화
- 사전처리에서 **사후처리**
- 표본조사에서 **전수조사**
- 질보다 **양**
- 인과관계에서 **상관관계**로


#### 빅데이터 분석 프로세스
- 빅데이터 수집-빅데이터 저장 및 관리-빅데이터 처리-빅데이터 분석-시각화 및 활용-데이터 폐기


#### 비식별 조치 단계
- 적정성 평가 방법으로 k-익명성 모델을 최소한의 평가 수단으로 정의하고 있음
- 개인정보 보호 모델에는 k-익명성과 이를 보완한 l-다양성, t-근접성 모델이 있으며 최소한 k-익명성 모델을 적용하여 적정성으로 평가해야 한다.


#### 빅데이터의 위기 요인
- **사생활 침해** : 개인정보 주체의 의도와 상관없이 개인의 민감한 정보를 누출시켜 사생활 침해로 이어질 수 있다.
- **책임 원칙 훼손** : 범죄 예측, 위험 요소 예측 등이 가능해지면서 사건이 발생하기 전에 그 행위에 대한 책임을 물어 불이익을 주는 행위
- **데이터 오용** : 잘못된 분석으로 인해 피해가 발생하는 형태


**개인 정보 비식별 조치 가이드라인**은 데이터 활용이 증가함에 따라 개인정보 보호 강화에 대한 요구가 지속되어 개인정보 보호를 보장하면서 데이터를 활용하기 위해 만들어졌으며, 개인정보를 이용 또는 제공할 때 준수해야 할 조치 기준을 제시하고 있다.


#### 반정형 데이터
- 형식과 구조가 변경될 수 있지만 데이터 구조 정보를 함께 제공하는 형식의 데이터
- 유형에는 HTML, JSON, 로그 데이터, 센싱 데이터 등이 있다.


## 2. 데이터 분석 계획
#### 분석 문제 정의 방식
- **하향식 접근 방식** : 문제가 정의되어 주어지고 이에 대한 해결 방법을 찾기위해 단계적으로 업무를 수행하는 방식
  - 문제 탐색-분석 문제 정의-해결 방안 탐색-타당성 평가-과제 선정
- **상향식 접근 방식** : 문제를 정의할 수 없는 경우 데이터를 기반으로 문제를 정의하고 해결 방안을 탐색하는 방식

#### 하향식 접근법
- 문제 탐색
  - 비즈니스 모델 기반 문제 탐색 : 기업 내/외부 환경을 포괄하는 비즈니스 모델의 업무 단위로 문제를 발굴하는 방법
  - 외부 참조 모델 기반 문제 탐색 : 외부 사례를 벤치마킹하여 분석 기회를 발굴하는 방법
- 분석 문제 정의 : 비즈니스 문제를 데이터의 문제로 전환
- 해결 방안 탐색 : 문제의 수준 및 분석역량에 기초하여 분석기법 및 방법 탐색
- 타당성 평가 및 과제 선정 : 데이터와 기술의 타당성, 경제성을 고려하여 여러 대안 중 적합한 대안을 선택


#### 디자인 사고(Design Thinking)
- 상향식 접근법으로 문제를 도출하고 하향식 접근법으로 해결방법을 찾는 과정을 반복함으로 동적인 환경에서 최적의 문제 정의를 하기 위한 접근방식


#### 문제 분석 해결 방안
- 최적화 : **분석 대상과 분석 방법을 알 경우** 개선을 통한 최적화
- 솔루션 : **분석 대상은 알지만 분석 방법을 모를 경우** 분석 주제에 대한 솔루션 탐색
- 통찰 : **분석 대상이 무엇인지 정확히 모르지만 기존에 알고 있는 분석 방법**을 활용하여 새로운 통찰 도출
- 발견 : **분석의 대상과 방법을 모두 모를 경우** 분석의 대상을 탐색하여 발견


#### 데이터 분석 방안-데이터 분석 업무 흐름
1. 데이터 수집 : 분석에 필요한 데이터의 원천과 활용 여부를 판단하여 분석에 활용할 데이터를 수집
2. 데이터 저장 : 수집된 데이터를 분석 아키텍처에 저장
3. 데이터 처리 : 전처리와 후처리를 통해 데이터를 분석 환경과 목적에 적합하게 가공
4. 탐색적 데이터 분석(EDA) : 데이터 현황을 분포도, 평균과 분산 등 간단한 시각화나 통계 지표를 활용하여 특성을 파악하고 분석 방향을 수립
5. 모형 및 알고리즘 설계 : 데이터 특성에 맞는 분석 모형과 알고리즘 설계 및 분석 실행
6. 시각화 및 보고서를 통한 데이터 활용 : 분석 결과를 현업이 이해하기 쉽도록 그래프/차트를 통해 시각화하여 보고서 작성


#### 추가 분석 방법론
- **KDD**(Knowledge Discovery in Database) : 데이터로부터 통계적인 패턴이나 지식을 찾기 위해 정리된 데이터 마이닝 프로세스로 데이터 선택, 데이터 전처리, 데이터 변환, 데이터 마이닝, 해석과 평가의 단계로 진행됨
- **CRISP-DM**(Cross Industry Standard Process for Data Mining) : **단계(최상위 단계)**, 일반화 태스크, 세분화 태스크, 프로세스 실행으로 구성되어 있따. 업무 이해, 데이터 이해, 데이터 준비, 모델링, 평가, 전개의 6단계로 진행되며 각 단계 피드백을 통해 완성도를 높일 수 있다.


## 3. 데이터 수집 및 저장 계획
#### 데이터 수집 프로세스
- 데이터 수집은 **수집 대상 선정, 데이터 수집 세부계획 수립, 테스트 수집 실행**의 프로세스로 나뉜다.

####  데이터 수집 기술
- 정형 데이터 :FTP, Open API
- 비정형 데이터 : Crawling, RSS, Open API, FTP, Scrapy, Apache Kafka
- 반정형 데이터 : Sensing, Streaming, Flume, Scribe, Chukwa

#### 데이터 유형-구조
- **정형 데이터** : 정형화된 스키마 구조를 가지고 고정된 필드에 저장되는 행과 열로 구성된 데이터
  - 관계형 데이터베이스, 스프레드 시트 등이 존재
- **반정형 데이터** : 스키마 구조 형태를 가지고 메타데이터를 포함하며, 값과 형식이 일관되지 않은 데이터
  - XML, HTML, 웹 로그, 알람, JSON, RSS, 센서 데이터 등
- **비정형 데이터** : 스키마 구조 형태 없이 고정된 필드에 저장되지 않는 데이터
  - SNS, 웹 게시판, 텍스트/이미지/오디오/비디오 등


#### 데이터 속성 파악
- **범주형 데이터** : 조사 대상을 특성에 따라 범주로 구분하여 측정된 변수. 연산 적용이 불가하며 명목형과 순서형으로 구분된다.
  - **명목형** : 변수의 크기가 순서와 상관없이 의미만 구분하는 경우
  - **순서형** : 변수의 값이 기준에 따라 순서를 의미하는 경우
  - 범주형 데이터는 명목 척도, 서열 척도, 등간 척도를 사용함
- **수치형 데이터** : 수치로 측정되는 변수로 연산이 가능하며 이산형과 연속형으로 구분된다.
  - **이산형** : 변수가 취할 수 있는 값을 하나하나 셀 수 있는 경우
  - **연속형** : 변수가 구간 안의 모든 값을 가질 경우
  - 수치형 데이터는 비율 척도, 등간 척도를 사용함


- 명목 척도 : 표본의 특징에 따라 범주를 분류하기 위해 수량적 변수로 바꾸어 놓은 것*(남자는 1, 여자는 2)*
- 서열 척도 : 어떤 특성에 대한 대상을 상대적으로 평가하여 순위 관계를 결정하는 척도*(매우 나쁨 1, 나쁨 2, 보통 3, 좋음 4, 매우 좋음 5)*
- 등간 척도 : 주로 범주형 데이터를 정량적으로 측정하기 위해 사용. 절대 영점이 없다.*(시각, 온도 등이 해당)*
- 비율 척도 : 어떤 특징에 부여한 숫자로써 일정한 간격을 보이며 절대 영점이 존재하는 척도. *키, 무게, 수량, 길이* 등이 이에 해당


#### 데이터 처리 기술
- 데이터 필터링 : 오류 탐색, 보정, 삭제 및 중복 확인 등의 과정을 통해 데이터 품질을 향상시키는 기술
- 데이터 변환 : 데이터 유형 등을 변환하여 저장, 분석에 용이한 형태로 변환하는 기술
  - 평활화 : 데이터의 노이즈를 구간화, 군집화 등으로 다듬는 기법
  - 집계 : 다양한 차원으로 데이터를 요약하는 기법
  - 일반화 : 특정 구간으로 값을 스케일링하는 기법
  - 정규화 : 정해진 구간으로 전환하는 기법
  - 속성 생성 : 새로운 속성 값을 생성하는 기법
- 데이터 정제 : 결측치들을 채우고 이상치를 식별하여 제거하는 기술
- 데이터 통합 : 연계가 필요한 추가 속성을 통합하는 기술
- 데이터 축소 : 분석에 불필요한 항목 등을 제거하는 기술


#### 데이터 보안 관리
- 사용자 인증 : ID와 비밀번호 인증, 일회용 패스워드, 전자인증, 통합사용자 인증 등의 기술로 미리 정한 기준에 따라 사용자의 접근자격을 확인하는 기술
- 접근제어 : 객체에 대한 읽기, 쓰기 등의 작업을 할 때 그 객체에 대한 권한을 확인하고 통제하는 기술
- 암호화 : 암호화 알고리즘을 통해 데이터를 변경하여 해독 불가능한 상태로 만드는 기술
- 개인정보 비식별화 : 수집된 개인정보의 일부 또는 전부를 처리하여 개인을 특정할 수 없도록 처리하는 기술
- 개인정보 암호화 : 데이터베이스상에서 개인정보가 포함된 특정 필드를 암호화하여 저장하는 기술


#### 데이터 품질의 종류
- 정확성 : 현실의 값이 정의된 기준에 맞도록 저장되어 있는 특성
- 유효성 : 데이터가 정해진 유효기준을 충족하는 특성
- 완전성 : 데이터의 필수 항목에 누락이 없는 특성
- 정합성 : 시스템 내의 동일한 데이터가 서로 일치하는 특성
- 유일성 : 데이터의 구분 기준에 따라 중복이 없는 특성
- 유용성 : 사용자가 만족할 말한 수준의 최신 데이터가 쉽게 접근하여 사용될 수 있는 특성
- 적시성 : 사용자가 필요한 시점에 지연 없이 데이터를 제공하는 특성
- 보안성 : 데이터의 접근이 적절히 통제되고 개인정보에 대한 보안 조치나 중요 데이터를 보호하고 있는 특성
- 안정성 : 에러, 장애의 발생 가능성을 최소화하고 사전 차단이나 그로 인한 지연을 최소화할 수 있는 특성
- 일관성 : 데이터의 구조, 값, 형태가 일관되게 정의되어 있는 특성


#### 데이터의 적재 및 저장
- 데이터 적재는 수집한 원천데이터를 저장한 상태로 **데이터의 추출(Extraction), 변환(Transformation), 적재의(Loading)** 과정을 거치며 ETL 작업이라고도 한다.(ETL 작업은 **정형 데이터의 수집 기술**에 해당함)
- 데이터 저장은 저장할 데이터의 유옇에 따라 저장관리에 유리한 저장방식을 결정한다.
  - 정형 데이터는 관계형 데이터베이스, 반정형 데이터는 NoSQL, 비정형 데이터는 분산 파일 시스템을 주로 사용한다.


#### 데이터 저장 플랫폼
- 데이터 웨어 하우스 : 기업의 업무 시스템에서 발생하는 방대한 데이터를 통합 관리하여 의사결정 도구의 기초 데이터로 사용되는 데이터의 집합체
  - 데이터 마트 : 데이터 웨어하우스에서 정의된 접근계층. 특정 리포트나 조직에서 사용하기 위한 특정 주제 영역의 데이터
- 데이터 레이크 : 데이터 분석의 영역이 비정형 등 다양한 유형의 데이터 분석으로 확장됨에 따라 기존 데이터 웨어하우스에서 확장된 데이터 저장, 관리 활동이 필요하게 됨. 정형 데이터 뿐만이 아닌 다양한 반정형, 비정형 데이터를 수집/정제/통합하여 분석에 활용하기 위해 다양한 유형의 데이터를 저장할 수 있는 저장소


#### 개인정보 비식별 조치 가이드라인의 적정성 평가 단계
- 기초 자료 구성-평가단 구성-평가 수행-추가 비식별 조치-데이터 활용