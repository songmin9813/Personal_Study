# 4. 빅데이터 결과 해석
## 1. 분석 모형 평가 및 개선
#### 회귀모형 평가지표
1. 평가 지표
- 평균 절대 오차(MAE : Mean Absolute Error) : 실제 값과 예측 값의 차이(오차)에 절댓값을 취해 평균한 값. 직관적이나 에러의 크기가 그대로 반영됨
- 평균 제곱 오차(MSE : Mean Squared Error) : 모형의 실제 값과 예측 값의 차이를 제곱하여 평균한 값
- 평균제곱근오차(RMSE : Root Mean Squared Error) : MSE에 제곱근을 씌운 값. MSE는 실 오류의 평균보다 값이 더 커지는 경향이 있어 MSE에 제곱근을 씌운 형태를 사용함
- 평균절대백분율오차(MAPE : Mean Absolute Percentage Error) : MAE를 퍼센트로 변환한 값. 오차를 비율로 나타내어 단위가 다른 변수 간에 오차를 비교할 수 있음

2. 결정계수(Coefficient of determination, R^2)
- 선형 회귀 모형이 실제 데이터를 얼마나 잘 설명하는지를 나타내는 지표. 결정계수 값이 1에 가까울수록 모형의 설명력이 높다.
- SST(Total Sum of Squares) : 전체제곱합. 실제 관측치와 y값들의 평균의 차이를 제곱하여 합한 값
- SSR(Regression Sum of Squares) : 회귀제곱합. 모형의 예측치와 y값들의 평균의 차이를 제곱하여 합한 값
- SSE(Error Sum of Squares) : 오차제곱합. 실제 관측치와 모형의 예측치의 차이를 제곱하여 합한 값

#### 분류 모형 평가 지표 - 기출
1. 혼동 행렬(Confusion Matrix)
- 분류모형이 예측한 값과 실제 값의 조합을 표 형태로 나타낸 것. 예측 값과 실제 값의 참/거짓 조합에 따라 TP, FN, FP, TN 네 가지로 구분한다.
2. 평가 지표
- 혼동행렬을 구한 후 아래의 다양한 평가 지표를 계산할 수 있다.
- 정확도(Accuracy) : 전체 데이터 중 예측을 정확하게 한 데이터의 비율
- 정밀도(Precision) : Positive로 예측한 데이터 중 실제 Positive인 데이터의 비율
- 재현율, 민감도(Recall, Sensitivity) : 실제 Positive인 데이터 중 모형이 Positive로 예측한 데이터의 비율
- 특이도(Specificity) : 실제 Negative인 데이터 중 모형이 Negative로 예측한 데이터의 비율
  - 거짓 긍정률(FPR) = 1-특이도
- F-1 Score : 정밀도와 재현율의 조화평균
- 거짓 긍정률(FPR, False Positive Rate) : 실제 Negative인 데이터 중 모형이 Positive로 예측한 데이터의 비율
- 참 긍정률(TPR, True Positive Rate) : 실제 Positive인 데이터 중 모형이 Positive로 예측한 데이터의 비율

3. ROC 곡선(Receiver Operating Characteristic curve)
- 임계값을 0에서 1까지 변화시켜 가면서 x축에는 거짓 긍정률, y축에는 참 긍정률을 표시해서 그린 곡선
- 임계값이 변화함에 따라 Positive/Negative 분류 여부가 달라지므로 ROC 곡선도 다르게 나타난다.


#### 분석 모형 진단
- 선형성 : 종속변수는 독립변수의 선형 함수다.
- 독립성 : 독립변수 사이에는 상관관계가 없어야 한다.
- 등분산성 : 오차항의 분산은 등분산이다.
- 정규성 : 오차항의 평균은 0이다.


#### 교차 검증
- k-fold 교차 검증 : 데이터를 k개의 fold로 나누어 k-1개는 학습에, 나머지 한 개는 검증에 사용한다. 
- 홀드아웃 교차 검증 : 데이터를 무작위로 7:3 또는 8:2의 비율로 학습 데이터와 검증 데이터로 나누는 방법
- 리브-p-아웃 교차검증 : 데이터 중 p개의 관측치만 검증 데이터로 사용하고 나머지는 학습 데이터로 사용하는 방법


#### 모수 유의성 검정(Significance test)
- 수집된 자료가 통계적으로 유의한지 판단하는 과정. 수집된 자료의 모집단에 대해 가설을 설정하고 그 가설이 맞는지 확인한다. 그 가설이 모집단의 분포를 가정하는 것이면 모수 검정, 아니면 비모수 검정이라 한다.
- 모수 검정 : 모집단의 분포를 가정하고 표본의 평균, 표준 편차 등을 이용하여 집단 간 차이를 검정하는 방법
- 비모수 검정 : 모집단의 분포를 가정하지 않고 집단 간 차이를 검정하는 방법


#### 적합도 검정
1. Q-Q plot
- 관측치의 분포가 정규분포에 얼마나 가까운지 시각적으로 표현하는 데 사용. y축은 데이터를 표준화한 z값, x축은 표준정규분포에서의 해당 분위수를 말한다. Q-Q plot 위에 나타낸 데이터가 대각선 형태의 참조선에 가깝게 보이면 관측치의 분포가 정규분포에 가깝다 볼 수 있다.
2. 카이제곱 검정(Chi - Squared Test) - 기출
- 어떤 그룹이 서로 독립인지 아닌지 확인하는 방법. 카이제곱 검정은 목적에 따라 독립성 검정, 적합성 검정, 동일성 검정으로 나뉜다. 현재의 설명은 적합성 검정을 위주로 설명함
  - 적합성 검정 : 모집단의 분포가 내가 생각한 분포와 동일한가?
  - 독립성 검정 : 두 변수는 서로 독립적인가?
  - 동일성 검정 : 두 집단의 분포가 동일한가?
- 카이제곱 검정은 범주형 데이터에 사용되며 데이터가 예상되는 분포에 얼마나 잘 맞는지를 검정한다.

3. 샤피로 윌크 검정(Shapiro - Wilk Normality Test) : 데이터의 정규성을 검증하는 방법
4. 콜모고로프 스미로노프 검정 : 데이터가 예상되는 분포에 얼마나 잘 맞는지를 검정. 데이터의 누적분포함수와 예상 분포의 누적분포함수를 비교하기에 연속형 데이터에서 적용이 가능하다.


#### 과대 적합과 과소 적합
- 과대적합 : 분석 모형이 학습 데이터에 지나치게 적합하여 일반화되지 않는 것을 말함. 학습 데이터의 특성을 필요 이상으로 담은 복잡한 모형이 만들어졌다 생각할 수 있음
- 과대적합의 방지 : 학습 데이터 수 증가, 가중치 규제, 교차 검증 등의 방법을 통하여 이를 해결한다.
  - 학습 데이터 수 증가 : 충분한 양의 데이터를 학습하도록 기간을 늘리거나 오버 샘플링 기법을 사용한다.
  - 가중치 규제 : 가중치 값을 제한하여 변수의 수를 줄이는 효과를 낸다.
  - 교차 검증 : 검증 데이터를 매번 다르게 사용하기에 하나의 검증 데이터에 과대적합할 가능성을 낮춰준다.

#### 매개변수 최적화
- 분석 모형을 학습하는 것은 학습 데이터부터 손실함수의 값을 가장 작게 만드는 매개변수의 최적값을 찾아 나가는 과정이다.
- 손실함수 값은 구하기 복잡하고, 분석 모형의 매개변수 개수도 많아 매개변수의 최적값을 구하는 것은 어렵다.
1. 경사하강법(Gradient descent)
- 가중치 매개변수에 대한 손실함수의 기울기를 통해 최적값을 구하는 방법
- 매개변수 벡터에 대해 손실함수의 현재 기울기를 계산하고, 기울기가 감소하는 방향으로 매개변수 값을 갱신한다. 갱신을 반복하다 기울기가 0이 되는 순간이 손실함수가 최소화되는 매개변수 값이 된다.
- 현재는 확률적 경사하강법을 개선한 다양한 옵티마이저가 사용된다.(모멘텀, Adagrad, RMSProp 등)

2. 모멘텀(Momentum) : 확률적 경사하강법의 매개변수 변경 방향에 가속도를 부여해주는 방식
3. AdaGrad(Adaptive Gradient) : 매개변수 값을 업데이트하면서 각 변수마다 학습률이 다르게 적용하는 방법. 초깃값에서 이미 값이 많이 변한 매개변수는 최적값에 가까워졌다고 생각하고 학습률을 작게 하여 값을 미세하게 조절한다.
4. RMSProp :  AdaGrad에서 최적값에 도달하기 전에 학습률이 0에 가까워지는 상황을 방지하기 위하여 개선된 방법. 새로운 하이퍼파라미터 p를 도입하여 h에서 기울기를 더할 때 단순 누적이 아니라 지수가중이동평균값을 더한다.
5. Adam(Adaptive moment estimation) : 모멘텀과 RMSProp이 합쳐진 형태. 최근 가장 많이 사용되는 옵티마이저


#### 분석 모형 융합(=앙상블)
- 보팅 : 여러 개의 분석 모형 결과를 종합하는 방법.
  - 직접 투표(Hard Voting) : 많이 선택된 클래스를 최종 결과로 예측하는 방법
  - 간접 투표(Soft Voting) : 각 모형의 클래스 확률 값을 평균내어 확률이 가장 높은 클래스를 최종 결과로 예측하는 방법

- 배깅(Bagging) : bootstrap aggregating의 줄임말. 학습 데이터에서 일정한 크기의 부트스트랩 샘플을 무작위로 복원 추출. 이를 이용해 분석 모형을 각각 학습한 후 학습한 결과를 종합하여 최종 분석 모형을 구한다. 대표 알고리즘으로 Random Forest가 있음
- 부스팅(Boosting) : 약한 분석 모형을 여러 개 연결해서 강한 분석 모형을 만드는 방법. 정답에는 낮은 가중치를, 오답에는 높은 가중치를 두어 오답을 더 잘 맞출 수 있도록 학습을 시킨다. 대표 알고리즘으로 Adaboost, XGBoost, LightBGM이 있음
- 스태킹(Stacking) : 여러 분석 모형의 예측을 종합하는 방식으로 모형을 사용함. 학습 데이터로 여러 개의 분석 모형을 만든 후 각 분석 모형의 예측값들을 독립변수로 하는 최종 예측 모형을 학습시킨다.

#### 최종 모형 선정
- 최종모형 평가 기준 선정 : 분석 모형 개발이 완료된 후 최종모형을 선정하기 위한 평가 기준을 정함. 정확도, 정밀도, 재현율 등 일반적으로 분석모형 평가에 사용하는 성능지표를 사용함
- 분석모형 평가 : 분석모형 최종 평가를 위해 훈련에 사용하지 않았던 데이터를 사용함
- 최종모형 선정 : 분석가, 비즈니스 업무 담당자, 데이터 처리자 등 관련 인원들이 함께 모여 분석모형 평가 결과를 놓고 최종모형을 선정함


#### 오답
- 이상치가 있는 데이터에서는 오차를 제곱하여 계산하는 지표보다 절댓값을 취하여 계산하는 지표가 더 유리하다.
- 과대적합은 분석 모형의 편향이 높고 분산이 낮은 상태이다. 
- AdaGrad(확률적 경사하강법)은 배치의 크기가 1인 배치 경사하강법으로 볼 수 없다.
- 데이터의 정규성을 판단하는 데 활용하는 지표로 히스토그램, Q-Q plot, 샤피로-윌크 검정을 통해 알아낼 수 있다. 카이제곱 검정으로는 알아낼 수 없음